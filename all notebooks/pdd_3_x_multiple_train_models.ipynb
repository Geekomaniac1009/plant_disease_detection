{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323},{"sourceId":8138661,"sourceType":"datasetVersion","datasetId":4811534},{"sourceId":8138718,"sourceType":"datasetVersion","datasetId":4811577},{"sourceId":8138755,"sourceType":"datasetVersion","datasetId":4811609},{"sourceId":8138779,"sourceType":"datasetVersion","datasetId":4811630},{"sourceId":8138803,"sourceType":"datasetVersion","datasetId":4811652},{"sourceId":8139784,"sourceType":"datasetVersion","datasetId":4812385}],"dockerImageVersionId":29845,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Hi there** ,\n\nThis Notebook will deal with an implementation of \n5 Layered CNN architecture\n* **Resnet**\n* **VGG16**\n* **VGG19**\n* **Imagnet**\n* **Inception Model**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-16T21:14:45.644727Z","iopub.execute_input":"2024-04-16T21:14:45.645125Z","iopub.status.idle":"2024-04-16T21:14:45.655572Z","shell.execute_reply.started":"2024-04-16T21:14:45.645069Z","shell.execute_reply":"2024-04-16T21:14:45.654632Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input/plantvillage-dataset/color\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:14:45.916088Z","iopub.execute_input":"2024-04-16T21:14:45.917045Z","iopub.status.idle":"2024-04-16T21:14:45.926848Z","shell.execute_reply.started":"2024-04-16T21:14:45.916684Z","shell.execute_reply":"2024-04-16T21:14:45.925706Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['Tomato___Late_blight',\n 'Tomato___healthy',\n 'Grape___healthy',\n 'Orange___Haunglongbing_(Citrus_greening)',\n 'Soybean___healthy',\n 'Squash___Powdery_mildew',\n 'Potato___healthy',\n 'Corn_(maize)___Northern_Leaf_Blight',\n 'Tomato___Early_blight',\n 'Tomato___Septoria_leaf_spot',\n 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n 'Strawberry___Leaf_scorch',\n 'Peach___healthy',\n 'Apple___Apple_scab',\n 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n 'Tomato___Bacterial_spot',\n 'Apple___Black_rot',\n 'Blueberry___healthy',\n 'Cherry_(including_sour)___Powdery_mildew',\n 'Peach___Bacterial_spot',\n 'Apple___Cedar_apple_rust',\n 'Tomato___Target_Spot',\n 'Pepper,_bell___healthy',\n 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n 'Potato___Late_blight',\n 'Tomato___Tomato_mosaic_virus',\n 'Strawberry___healthy',\n 'Apple___healthy',\n 'Grape___Black_rot',\n 'Potato___Early_blight',\n 'Cherry_(including_sour)___healthy',\n 'Corn_(maize)___Common_rust_',\n 'Grape___Esca_(Black_Measles)',\n 'Raspberry___healthy',\n 'Tomato___Leaf_Mold',\n 'Tomato___Spider_mites Two-spotted_spider_mite',\n 'Pepper,_bell___Bacterial_spot',\n 'Corn_(maize)___healthy']"},"metadata":{}}]},{"cell_type":"code","source":"EPOCHS = 5\nINIT_LR = 1e-3\nBS = 32\ndefault_image_size = tuple((224, 224))\nimage_size = 0\ndirectory_root = '/kaggle/input/plantvillage-dataset/'\nwidth=224\nheight=224\ndepth=3","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-04-16T21:48:39.954058Z","iopub.status.idle":"2024-04-16T21:48:39.954765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:49:00.648830Z","iopub.execute_input":"2024-04-16T21:49:00.649246Z","iopub.status.idle":"2024-04-16T21:49:00.657503Z","shell.execute_reply.started":"2024-04-16T21:49:00.649189Z","shell.execute_reply":"2024-04-16T21:49:00.656485Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"image_list, label_list, classes = [], [], []\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n\n    for plant_folder in ['color/'] :\n        print(plant_folder)\n        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n        print(plant_disease_folder_list)\n        for disease_folder in plant_disease_folder_list :\n            # remove .DS_Store from list\n            if disease_folder == \".DS_Store\" :\n                plant_disease_folder_list.remove(disease_folder)\n\n        for plant_disease_folder in plant_disease_folder_list:\n            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}\")\n            for single_plant_disease_image in plant_disease_image_list :\n                if single_plant_disease_image == \".DS_Store\" :\n                    plant_disease_image_list.remove(single_plant_disease_image)\n\n            for image in plant_disease_image_list:\n                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                    image_list.append(convert_image_to_array(image_directory))\n                    label_list.append(plant_disease_folder)\n            classes.append(plant_disease_folder)\n    print(\"[INFO] Image loading completed\")  \nexcept Exception as e:\n    print(f\"Error --- : {e}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(classes)    ","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:18:51.154867Z","iopub.execute_input":"2024-04-16T21:18:51.155525Z","iopub.status.idle":"2024-04-16T21:18:51.162534Z","shell.execute_reply.started":"2024-04-16T21:18:51.155461Z","shell.execute_reply":"2024-04-16T21:18:51.161022Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"38"},"metadata":{}}]},{"cell_type":"code","source":"classes","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:23:11.232230Z","iopub.execute_input":"2024-04-16T21:23:11.232672Z","iopub.status.idle":"2024-04-16T21:23:11.240342Z","shell.execute_reply.started":"2024-04-16T21:23:11.232612Z","shell.execute_reply":"2024-04-16T21:23:11.239270Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"['Tomato___Late_blight',\n 'Tomato___healthy',\n 'Grape___healthy',\n 'Orange___Haunglongbing_(Citrus_greening)',\n 'Soybean___healthy',\n 'Squash___Powdery_mildew',\n 'Potato___healthy',\n 'Corn_(maize)___Northern_Leaf_Blight',\n 'Tomato___Early_blight',\n 'Tomato___Septoria_leaf_spot',\n 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n 'Strawberry___Leaf_scorch',\n 'Peach___healthy',\n 'Apple___Apple_scab',\n 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n 'Tomato___Bacterial_spot',\n 'Apple___Black_rot',\n 'Blueberry___healthy',\n 'Cherry_(including_sour)___Powdery_mildew',\n 'Peach___Bacterial_spot',\n 'Apple___Cedar_apple_rust',\n 'Tomato___Target_Spot',\n 'Pepper,_bell___healthy',\n 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n 'Potato___Late_blight',\n 'Tomato___Tomato_mosaic_virus',\n 'Strawberry___healthy',\n 'Apple___healthy',\n 'Grape___Black_rot',\n 'Potato___Early_blight',\n 'Cherry_(including_sour)___healthy',\n 'Corn_(maize)___Common_rust_',\n 'Grape___Esca_(Black_Measles)',\n 'Raspberry___healthy',\n 'Tomato___Leaf_Mold',\n 'Tomato___Spider_mites Two-spotted_spider_mite',\n 'Pepper,_bell___Bacterial_spot',\n 'Corn_(maize)___healthy']"},"metadata":{}}]},{"cell_type":"code","source":"image_size = len(image_list)\nimage_size","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:18:51.164369Z","iopub.execute_input":"2024-04-16T21:18:51.164887Z","iopub.status.idle":"2024-04-16T21:18:51.177871Z","shell.execute_reply.started":"2024-04-16T21:18:51.164659Z","shell.execute_reply":"2024-04-16T21:18:51.176707Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"54303"},"metadata":{}}]},{"cell_type":"code","source":"label_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\npickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nn_classes = len(label_binarizer.classes_)\nprint(label_binarizer.classes_)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:18:51.179547Z","iopub.execute_input":"2024-04-16T21:18:51.179916Z","iopub.status.idle":"2024-04-16T21:18:51.496537Z","shell.execute_reply.started":"2024-04-16T21:18:51.179858Z","shell.execute_reply":"2024-04-16T21:18:51.495461Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"['Apple___Apple_scab' 'Apple___Black_rot' 'Apple___Cedar_apple_rust'\n 'Apple___healthy' 'Blueberry___healthy'\n 'Cherry_(including_sour)___Powdery_mildew'\n 'Cherry_(including_sour)___healthy'\n 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot'\n 'Corn_(maize)___Common_rust_' 'Corn_(maize)___Northern_Leaf_Blight'\n 'Corn_(maize)___healthy' 'Grape___Black_rot'\n 'Grape___Esca_(Black_Measles)'\n 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)' 'Grape___healthy'\n 'Orange___Haunglongbing_(Citrus_greening)' 'Peach___Bacterial_spot'\n 'Peach___healthy' 'Pepper,_bell___Bacterial_spot'\n 'Pepper,_bell___healthy' 'Potato___Early_blight' 'Potato___Late_blight'\n 'Potato___healthy' 'Raspberry___healthy' 'Soybean___healthy'\n 'Squash___Powdery_mildew' 'Strawberry___Leaf_scorch'\n 'Strawberry___healthy' 'Tomato___Bacterial_spot' 'Tomato___Early_blight'\n 'Tomato___Late_blight' 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n 'Tomato___Spider_mites Two-spotted_spider_mite' 'Tomato___Target_Spot'\n 'Tomato___Tomato_Yellow_Leaf_Curl_Virus' 'Tomato___Tomato_mosaic_virus'\n 'Tomato___healthy']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Normalization Of images**","metadata":{}},{"cell_type":"code","source":"np_image_list = np.array(image_list, dtype=np.float16) / 225.0\nprint(\"[INFO] Spliting data to train, test\")\nx_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) ","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:18:51.500407Z","iopub.execute_input":"2024-04-16T21:18:51.500873Z","iopub.status.idle":"2024-04-16T21:19:53.405599Z","shell.execute_reply.started":"2024-04-16T21:18:51.500793Z","shell.execute_reply":"2024-04-16T21:19:53.404465Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[INFO] Spliting data to train, test\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:19:53.407577Z","iopub.execute_input":"2024-04-16T21:19:53.407911Z","iopub.status.idle":"2024-04-16T21:19:53.414979Z","shell.execute_reply.started":"2024-04-16T21:19:53.407857Z","shell.execute_reply":"2024-04-16T21:19:53.414053Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(38,)"},"metadata":{}}]},{"cell_type":"code","source":"x_train[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:19:53.416893Z","iopub.execute_input":"2024-04-16T21:19:53.417273Z","iopub.status.idle":"2024-04-16T21:19:53.430903Z","shell.execute_reply.started":"2024-04-16T21:19:53.417194Z","shell.execute_reply":"2024-04-16T21:19:53.429724Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(128, 128, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Augmentation Of data**","metadata":{}},{"cell_type":"code","source":"aug = ImageDataGenerator(\n    rotation_range=25, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, \n    zoom_range=0.2,horizontal_flip=True, \n    fill_mode=\"nearest\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:19:53.432809Z","iopub.execute_input":"2024-04-16T21:19:53.433204Z","iopub.status.idle":"2024-04-16T21:19:53.445305Z","shell.execute_reply.started":"2024-04-16T21:19:53.433126Z","shell.execute_reply":"2024-04-16T21:19:53.443935Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# ***5 Layer CNN Algorithm ***","metadata":{}},{"cell_type":"code","source":"model = Sequential()\ninputShape = (height, width, depth)\nchanDim = -1\nif K.image_data_format() == \"channels_first\":\n    inputShape = (depth, height, width)\n    chanDim = 1\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(n_classes))\nmodel.add(Activation(\"softmax\"))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:19:53.447473Z","iopub.execute_input":"2024-04-16T21:19:53.447918Z","iopub.status.idle":"2024-04-16T21:19:54.131666Z","shell.execute_reply.started":"2024-04-16T21:19:53.447845Z","shell.execute_reply":"2024-04-16T21:19:54.129545Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 128, 128, 32)      0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 128, 128, 32)      128       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 42, 42, 32)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 42, 42, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 42, 42, 64)        18496     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 42, 42, 64)        0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 42, 42, 64)        256       \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 42, 42, 64)        36928     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 42, 42, 64)        0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 42, 42, 64)        256       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 21, 21, 64)        0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 21, 21, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 21, 21, 128)       73856     \n_________________________________________________________________\nactivation_4 (Activation)    (None, 21, 21, 128)       0         \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 21, 21, 128)       512       \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 21, 21, 128)       147584    \n_________________________________________________________________\nactivation_5 (Activation)    (None, 21, 21, 128)       0         \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 21, 21, 128)       512       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 10, 10, 128)       0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 12800)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1024)              13108224  \n_________________________________________________________________\nactivation_6 (Activation)    (None, 1024)              0         \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 1024)              4096      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 38)                38950     \n_________________________________________________________________\nactivation_7 (Activation)    (None, 38)                0         \n=================================================================\nTotal params: 13,430,694\nTrainable params: 13,427,814\nNon-trainable params: 2,880\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Optimizer**","metadata":{}},{"cell_type":"code","source":"opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n# distribution\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n# train the network\nprint(\"[INFO] training network...\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:19:54.133507Z","iopub.execute_input":"2024-04-16T21:19:54.133875Z","iopub.status.idle":"2024-04-16T21:19:54.191649Z","shell.execute_reply.started":"2024-04-16T21:19:54.133807Z","shell.execute_reply":"2024-04-16T21:19:54.190637Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"[INFO] training network...\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) // BS,\n    epochs=5, verbose=1\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:14:32.807487Z","iopub.status.idle":"2024-04-16T21:14:32.807967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras import layers, Model\n\n# Define the input layer\ninput_layer = tf.keras.Input(shape=(224, 224, 3), name='input_2')\n\n# Define the DenseNet121 model with pretrained ImageNet weights\ndensenet_model = DenseNet121(weights='imagenet', include_top=False)\n\n# Set the trainable parameter to False\ndensenet_model.trainable = False\n\n# Pass the input through the DenseNet121 model\ndensenet_output = densenet_model(input_layer)\n\n# Add GlobalAveragePooling2D layer\nglobal_avg_pooling = layers.GlobalAveragePooling2D()(densenet_output)\n\n# Add Dense layer for classification\noutput_layer = layers.Dense(38, activation='softmax', name='dense')(global_avg_pooling)\n\n# Create the model\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n# Compile the model (if necessary)\n# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Print the summary of the model\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:45:44.320191Z","iopub.execute_input":"2024-04-16T21:45:44.320556Z","iopub.status.idle":"2024-04-16T21:45:56.274515Z","shell.execute_reply.started":"2024-04-16T21:45:44.320505Z","shell.execute_reply":"2024-04-16T21:45:56.273306Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\ndensenet121 (Model)          multiple                  7037504   \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 1024)              0         \n_________________________________________________________________\ndense (Dense)                (None, 38)                38950     \n=================================================================\nTotal params: 7,076,454\nTrainable params: 38,950\nNon-trainable params: 7,037,504\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights('/kaggle/input/densenet121-pdd-model-v1/densenet121pdd_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:47:22.050435Z","iopub.execute_input":"2024-04-16T21:47:22.050915Z","iopub.status.idle":"2024-04-16T21:47:22.759236Z","shell.execute_reply.started":"2024-04-16T21:47:22.050845Z","shell.execute_reply":"2024-04-16T21:47:22.758117Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#model.save('model5layercnnpdd.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:19:58.214383Z","iopub.execute_input":"2024-04-16T21:19:58.214852Z","iopub.status.idle":"2024-04-16T21:19:58.220420Z","shell.execute_reply.started":"2024-04-16T21:19:58.214708Z","shell.execute_reply":"2024-04-16T21:19:58.219051Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"image = convert_image_to_array('/kaggle/input/plantvillage-dataset/color/Tomato___healthy/000146ff-92a4-4db6-90ad-8fce2ae4fddd___GH_HL Leaf 259.1.JPG')\nimage = np.expand_dims(image, axis = 0)\nprint(image.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:50:59.275921Z","iopub.execute_input":"2024-04-16T21:50:59.276355Z","iopub.status.idle":"2024-04-16T21:50:59.289544Z","shell.execute_reply.started":"2024-04-16T21:50:59.276304Z","shell.execute_reply":"2024-04-16T21:50:59.287895Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"(1, 224, 224, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"prediction = model.predict(image)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:51:00.701936Z","iopub.execute_input":"2024-04-16T21:51:00.702655Z","iopub.status.idle":"2024-04-16T21:51:00.881221Z","shell.execute_reply.started":"2024-04-16T21:51:00.702571Z","shell.execute_reply":"2024-04-16T21:51:00.880146Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"prediction","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:51:01.322935Z","iopub.execute_input":"2024-04-16T21:51:01.323584Z","iopub.status.idle":"2024-04-16T21:51:01.334588Z","shell.execute_reply.started":"2024-04-16T21:51:01.323522Z","shell.execute_reply":"2024-04-16T21:51:01.332777Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"array([[5.9298141e-05, 5.0526167e-05, 7.3088362e-05, 8.6295448e-04,\n        1.4432958e-08, 1.8327624e-05, 8.5813506e-03, 3.2632956e-06,\n        4.2101906e-06, 2.2527824e-05, 5.6152180e-04, 3.3428162e-07,\n        1.4459977e-06, 7.0532442e-06, 4.4071578e-04, 2.9661587e-05,\n        2.9568456e-04, 8.0570629e-08, 1.5194784e-07, 8.7769717e-05,\n        2.1700932e-04, 1.5882117e-04, 5.5384706e-05, 9.3481259e-07,\n        5.0698850e-02, 5.5012974e-04, 1.0957169e-08, 2.1957824e-06,\n        9.5698156e-04, 2.7584008e-05, 1.1188285e-04, 2.9185131e-07,\n        2.8737481e-05, 3.2867814e-05, 6.1563128e-03, 1.8348687e-06,\n        1.8194839e-06, 9.2989832e-01]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"prediction.argmax()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:51:32.937777Z","iopub.execute_input":"2024-04-16T21:51:32.938319Z","iopub.status.idle":"2024-04-16T21:51:32.948537Z","shell.execute_reply.started":"2024-04-16T21:51:32.938243Z","shell.execute_reply":"2024-04-16T21:51:32.946371Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"37"},"metadata":{}}]},{"cell_type":"code","source":"classes[37]","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:51:46.555323Z","iopub.execute_input":"2024-04-16T21:51:46.555687Z","iopub.status.idle":"2024-04-16T21:51:47.293075Z","shell.execute_reply.started":"2024-04-16T21:51:46.555634Z","shell.execute_reply":"2024-04-16T21:51:47.291143Z"},"trusted":true},"execution_count":68,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-df4588414fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m37\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"code","source":"model.predict","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:50:31.759498Z","iopub.execute_input":"2024-04-16T21:50:31.759989Z","iopub.status.idle":"2024-04-16T21:50:31.768126Z","shell.execute_reply.started":"2024-04-16T21:50:31.759911Z","shell.execute_reply":"2024-04-16T21:50:31.766727Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"<bound method Model.predict of <tensorflow.python.keras.engine.training.Model object at 0x7f4e6e915d68>>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Results and Plots**","metadata":{}},{"cell_type":"code","source":"'''def Res_Plot_Test_Save(name):\n    print(\"[INFO] Plotting model accuracy and Loss\")\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(acc) + 1)\n    #Train and validation accuracy\n    plt.plot(epochs, acc, 'b', label='Training accurarcy')\n    plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n    plt.title('Training and Validation accurarcy')\n    plt.legend()\n\n    plt.figure()\n    #Train and validation loss\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and Validation loss')\n    plt.legend()\n    plt.show()\n    print(\"[INFO] Saving model\")\n    model.save(name)\n    '''\nprint(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]*100}\")\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.118982Z","iopub.status.idle":"2024-04-16T20:27:27.119680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Res_Plot_Test_Save('model5layercnnpdd1.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.121052Z","iopub.status.idle":"2024-04-16T20:27:27.121620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning Implementation\n\n### Transfer Learning Advantages\nTypically transfer learning enables us to build more robust models which can perform a wide variety of tasks.\n* Helps solve complex real-world problems with several constraints\n* Tackle problems like having little or almost no labeled data availability\n* Ease of transfering knowledge from one model to another based on domains and tasks\n* Provides a path towards achieving Artificial General Intelligence some day in the future!","metadata":{}},{"cell_type":"markdown","source":"**For References Check out**\n[https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a]","metadata":{}},{"cell_type":"markdown","source":"### **Inception ModelV3**\n\n##### Weights : Imagenet","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import Dense\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.utils.np_utils import to_categorical\n\n# Get the InceptionV3 model so we can do transfer learning\nbase_inception = InceptionV3(weights='imagenet', include_top=False, \n                             input_shape=(128, 128, 3))\n                             \n# Add a global spatial average pooling layer\nout = base_inception.output\nout = GlobalAveragePooling2D()(out)\nout = Dense(512, activation='relu')(out)\nout = Dense(512, activation='relu')(out)\npredictions = Dense(n_classes, activation='softmax')(out)\nmodel = Model(inputs=base_inception.input, outputs=predictions)\n\n# only if we want to freeze layers\nfor layer in base_inception.layers:\n    layer.trainable = False\n    \n# Compile \nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"]) \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.123012Z","iopub.status.idle":"2024-04-16T20:27:27.123503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) // BS,\n    epochs=EPOCHS, verbose=1\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.124789Z","iopub.status.idle":"2024-04-16T20:27:27.125399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('inceptionV3_modelpdd_v3_1.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.126665Z","iopub.status.idle":"2024-04-16T20:27:27.127378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Res_Plot_Test_Save('Inception_ModelV3_(Imagenet_Weights)_v4.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.128787Z","iopub.status.idle":"2024-04-16T20:27:27.129309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Resnet Model**\n\n##### Weights : Imagenet","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras import applications\nfrom keras.optimizers import Adam\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import Dense\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.utils.np_utils import to_categorical\n\n# Get the Resnet model so we can do transfer learning\nbase_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (128,128,3))\n                             \n# Add a global spatial average pooling layer\nout = base_model.output\nout = GlobalAveragePooling2D()(out)\nout = Dense(512, activation='relu')(out)\nout = Dense(512, activation='relu')(out)\npredictions = Dense(n_classes, activation='softmax')(out)\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# only if we want to freeze layers\nfor layer in base_inception.layers:\n    layer.trainable = False\n    \n# Compile \nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"]) \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.131011Z","iopub.status.idle":"2024-04-16T20:27:27.131587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) // BS,\n    epochs=5, verbose=1\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.133040Z","iopub.status.idle":"2024-04-16T20:27:27.133609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('resnet50_pdd_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.135218Z","iopub.status.idle":"2024-04-16T20:27:27.135722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Res_Plot_Test_Save('Resnet_With_Imagenet_Weights_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.137028Z","iopub.status.idle":"2024-04-16T20:27:27.137578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **VGG16 Model**\n\n##### Weights : Imagenet","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.applications import vgg16\nfrom keras.optimizers import Adam\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import Dense\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.utils.np_utils import to_categorical\n\n# Get the Resnet model so we can do transfer learning\nvgg = vgg16.VGG16(weights= None, include_top=False, input_shape= (128,128,3))\n                             \n# Add a global spatial average pooling layer\nout = base_model.output\nout = GlobalAveragePooling2D()(out)\nout = Dense(512, activation='relu')(out)\nout = Dense(512, activation='relu')(out)\npredictions = Dense(n_classes, activation='softmax')(out)\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# only if we want to freeze layers\nfor layer in base_inception.layers:\n    layer.trainable = False\n    \n# Compile \nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"]) \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.138901Z","iopub.status.idle":"2024-04-16T20:27:27.139341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) // BS,\n    epochs=5, verbose=1\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.140887Z","iopub.status.idle":"2024-04-16T20:27:27.141346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('vgg16_model_pdd1.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.142845Z","iopub.status.idle":"2024-04-16T20:27:27.143317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Res_Plot_Test_Save('VGG16_With_Imagenet_Weingts.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.145073Z","iopub.status.idle":"2024-04-16T20:27:27.145691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **VGG19 Model**\n\n##### Weights : Imagenet","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.applications import vgg19\nfrom keras.optimizers import Adam\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import Dense\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.utils.np_utils import to_categorical\n\n# Get the Resnet model so we can do transfer learning\nvgg = vgg19.VGG19(weights= None, include_top=False, input_shape= (128,128,3))\n                             \n# Add a global spatial average pooling layer\nout = base_model.output\nout = GlobalAveragePooling2D()(out)\nout = Dense(512, activation='relu')(out)\nout = Dense(512, activation='relu')(out)\npredictions = Dense(n_classes, activation='softmax')(out)\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# only if we want to freeze layers\nfor layer in base_inception.layers:\n    layer.trainable = False\n    \n# Compile \nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"]) \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.149974Z","iopub.status.idle":"2024-04-16T20:27:27.150683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) // BS,\n    epochs=15, verbose=1\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.152651Z","iopub.status.idle":"2024-04-16T20:27:27.153347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('vgg19_modelpdd_2.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.155229Z","iopub.status.idle":"2024-04-16T20:27:27.156105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Res_Plot_Test_Save('VGG19_Imagenet.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.157827Z","iopub.status.idle":"2024-04-16T20:27:27.158477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning Challenges\nTransfer learning has immense potential and is a commonly required enhancement for existing learning algorithms. Yet, there are certain pertinent issues related to transfer learning that need more research and exploration. Apart from the difficulty of answering the questions of what, when, and how to transfer, negative transfer and transfer bounds present major challenges.\n* Negative Transfer: The cases we have discussed so far talk about improvements in target tasks based on knowledge transfer from the source task. There are cases when transfer learning can lead to a drop in performance. Negative transfer refers to scenarios where the transfer of knowledge from the source to the target does not lead to any improvement, but rather causes a drop in the overall performance of the target task. There can be various reasons for negative transfer, such as cases when the source task is not sufficiently related to the target task, or if the transfer method could not leverage the relationship between the source and target tasks very well. Avoiding negative transfer is very important and requires careful investigation. In their work, Rosenstien and their co-authors present empirically how brute-force transfer degrades performance in target tasks when the source and target are too dissimilar. Bayesian approaches by Bakker and their co-authors, along with other techniques exploring clustering-based solutions to identify relatedness, are being researched to avoid negative transfers.\n* Transfer Bounds: Quantifying the transfer in transfer learning is also very important, that affects the quality of the transfer and its viability. To gauge the amount for the transfer, Hassan Mahmud and their co-authors used Kolmogorov complexity to prove certain theoretical bounds to analyze transfer learning and measure relatedness between tasks. Eaton and their co-authors presented a novel graph-based approach to measure knowledge transfer. Detailed discussions of these techniques are outside the scope of this article. Readers are encouraged to explore more on these topics using the publications outlined in this section!","metadata":{}},{"cell_type":"markdown","source":"# Model to json\n**inceptionV3**","metadata":{}},{"cell_type":"code","source":"import json\nfrom keras.models import load_model, model_from_json\n\n# Load the Keras model from .h5 file\nmodel = load_model('/kaggle/input/resnet50-model-pdd-v1/resnet50_pdd_model.h5')\n\n# Extract model architecture to JSON\nmodel_json = model.to_json()\n\n# Save the JSON to a file\nwith open(\"resnet50.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# Load the model architecture from JSON\nwith open('resnet50.json', 'r') as json_file:\n    loaded_model_json = json_file.read()\n\n# Recreate the Keras model from the JSON\nreconstructed_model = model_from_json(loaded_model_json)\n\n# Check if the model is compiled. If yes, compile it again.\nif hasattr(model, 'compile'):\n    reconstructed_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Evaluate the reconstructed model\nreconstructed_model.evaluate(x_test, y_test)  # Replace x_test, y_test with your test data\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.160359Z","iopub.status.idle":"2024-04-16T20:27:27.161272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model.h5 to pb and then .pb to json","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Load the Keras model from .h5 file\nkeras_model = tf.keras.models.load_model('/kaggle/input/densenet121-pdd-model-v1/densenet121pdd_model.h5')\n\n# Convert the Keras model to a TensorFlow model\nsession = tf.compat.v1.keras.backend.get_session()\n\n# Define the output node name\noutput_node_name = keras_model.output.op.name\n\n# Ensure that there is an output node\nif not output_node_name:\n    print(\"No output node found in the model.\")\n    exit()\n\n# Save the TensorFlow model using tf.saved_model\ntry:\n    tf.saved_model.save(keras_model, './saved_model')\n    print(\"Model successfully saved as a saved model.\")\nexcept Exception as e:\n    print(\"Error occurred during saving the model:\", str(e))\n    exit()\n\n# Load the saved model back\ntry:\n    loaded_model = tf.saved_model.load('./saved_model')\nexcept Exception as e:\n    print(\"Error occurred during loading the saved model:\", str(e))\n    exit()\n\n# Convert the loaded model to a TensorFlow graph\ngraph = tf.compat.v1.get_default_graph()\n\n# Get the concrete function for the loaded model\nconcrete_function = loaded_model.signatures['serving_default']\n\n# Freeze the TensorFlow graph\nfrozen_graph_def = tf.graph_util.convert_variables_to_constants(\n    session,\n    graph.as_graph_def(),\n    [output_node_name]\n)\n\n# Save the TensorFlow model as .pb file\ntry:\n    tf.io.write_graph(frozen_graph_def, '.', 'densenet121model.pb', as_text=False)\n    print(\"Model successfully saved as 'densenet121model.pb'\")\nexcept Exception as e:\n    print(\"Error occurred during saving the model:\", str(e))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:29:15.256433Z","iopub.execute_input":"2024-04-16T20:29:15.256980Z","iopub.status.idle":"2024-04-16T20:29:15.345890Z","shell.execute_reply.started":"2024-04-16T20:29:15.256889Z","shell.execute_reply":"2024-04-16T20:29:15.344482Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-68a52cbd4a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the Keras model from .h5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/densenet121-pdd-model-v1/densenet121pdd_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Convert the Keras model to a TensorFlow model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m--> 168\u001b[0;31m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       printable_module_name='layer')\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 292\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unknown layer: Functional"],"ename":"ValueError","evalue":"Unknown layer: Functional","output_type":"error"}]},{"cell_type":"code","source":"model = tf.keras.model.load_model('/kaggle/input/densenet121-pdd-model-v1/densenet121pdd_model.h5')\nmodel.export_TF()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:51:10.040374Z","iopub.execute_input":"2024-04-16T20:51:10.040721Z","iopub.status.idle":"2024-04-16T20:51:10.073722Z","shell.execute_reply.started":"2024-04-16T20:51:10.040667Z","shell.execute_reply":"2024-04-16T20:51:10.071961Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-12849af2f7cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/densenet121-pdd-model-v1/densenet121pdd_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_TF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core.keras' has no attribute 'model'"],"ename":"AttributeError","evalue":"module 'tensorflow_core.keras' has no attribute 'model'","output_type":"error"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras import layers\n\n# Define the number of classes\nclass_count = 38 # define your number of classes here\n\n# Define the model architecture\nfeats = DenseNet121(weights='imagenet', input_shape=(224, 224, 3), include_top=False)\nfeats.trainable = False\n\ninp = tf.keras.Input(shape=(224, 224, 3))\nx = feats(inp, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(class_count, activation='softmax')(x)\n\nmodel = tf.keras.Model(inp, x)\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Save the model in .h5 format\nmodel.save('your_model.h5')\n\n# Convert the Keras model to a TensorFlow graph\nsession = tf.compat.v1.keras.backend.get_session()\n\n# Define the output node name\noutput_node_name = model.output.op.name\n\n# Ensure that there is an output node\nif not output_node_name:\n    print(\"No output node found in the model.\")\n    exit()\n\n# Save the TensorFlow model using tf.saved_model\ntry:\n    tf.saved_model.save(model, './saved_model')\n    print(\"Model successfully saved as a saved model.\")\nexcept Exception as e:\n    print(\"Error occurred during saving the model:\", str(e))\n    exit()\n\n# Load the saved model back\ntry:\n    loaded_model = tf.saved_model.load('./saved_model')\nexcept Exception as e:\n    print(\"Error occurred during loading the saved model:\", str(e))\n    exit()\n\n# Convert the loaded model to a TensorFlow graph\ngraph = tf.compat.v1.get_default_graph()\n\n# Get the concrete function for the loaded model\nconcrete_function = loaded_model.signatures['serving_default']\n\n# Freeze the TensorFlow graph\nfrozen_graph_def = tf.compat.v1.graph_util.convert_variables_to_constants(\n    session,\n    graph.as_graph_def(),\n    [output_node_name]\n)\n\n# Save the TensorFlow model as .pb file\ntry:\n    tf.io.write_graph(frozen_graph_def, '.', 'your_model.pb', as_text=False)\n    print(\"Model successfully saved as 'your_model.pb'\")\nexcept Exception as e:\n    print(\"Error occurred during saving the model:\", str(e))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:45:05.514649Z","iopub.execute_input":"2024-04-16T20:45:05.515350Z","iopub.status.idle":"2024-04-16T20:46:44.726360Z","shell.execute_reply.started":"2024-04-16T20:45:05.515260Z","shell.execute_reply":"2024-04-16T20:46:44.724360Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n29089792/29084464 [==============================] - 1s 0us/step\nModel successfully saved as a saved model.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-7535504a0398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0moutput_node_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py\u001b[0m in \u001b[0;36mconvert_variables_to_constants\u001b[0;34m(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0;31m# This graph only includes the nodes needed to evaluate the output nodes, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m   \u001b[0;31m# removes unneeded nodes like those involved in saving and assignment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m   \u001b[0minference_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_sub_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_node_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0;31m# Identify the ops in the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py\u001b[0m in \u001b[0;36mextract_sub_graph\u001b[0;34m(graph_def, dest_nodes)\u001b[0m\n\u001b[1;32m    195\u001b[0m   name_to_input_name, name_to_node, name_to_seq_num = _extract_graph_summary(\n\u001b[1;32m    196\u001b[0m       graph_def)\n\u001b[0;32m--> 197\u001b[0;31m   \u001b[0m_assert_nodes_are_present\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_to_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0mnodes_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bfs_for_reachable_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_to_input_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py\u001b[0m in \u001b[0;36m_assert_nodes_are_present\u001b[0;34m(name_to_node, nodes)\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[0;34m\"\"\"Assert that nodes are present in the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_to_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s is not in graph\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: dense/Identity is not in graph"],"ename":"AssertionError","evalue":"dense/Identity is not in graph","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Define the directory you want to download\ndirectory_to_download = '/kaggle/working/saved_model'\n\n# Define the name for the zip file\nzip_file_name = 'densenet121model.zip'\n\n# Create a zip archive of the directory\nshutil.make_archive(zip_file_name.split('.')[0], 'zip', directory_to_download)\n\n# Download the zip file\nfrom IPython.display import FileLink\nFileLink(zip_file_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.165881Z","iopub.status.idle":"2024-04-16T20:27:27.166522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define the working directory path\nworking_dir = '/kaggle/working'\n\n# Get a list of all files and directories in the working directory\ncontents = os.listdir(working_dir)\n\n# Remove each file and directory in the working directory\nfor item in contents:\n    item_path = os.path.join(working_dir, item)\n    if os.path.isfile(item_path):\n        os.remove(item_path)\n    elif os.path.isdir(item_path):\n        shutil.rmtree(item_path)\n\nprint(\"Contents of the working directory have been cleared.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:27:27.168064Z","iopub.status.idle":"2024-04-16T20:27:27.168885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Load the functional model from the saved model directory\nloaded_model = tf.keras.models.load_model('/kaggle/input/densenet121-pdd-model-v1/densenet121pdd_model.h5')\n\n# Check the summary of the loaded model\nloaded_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:13:35.172738Z","iopub.execute_input":"2024-04-16T21:13:35.173356Z","iopub.status.idle":"2024-04-16T21:13:35.256720Z","shell.execute_reply.started":"2024-04-16T21:13:35.173287Z","shell.execute_reply":"2024-04-16T21:13:35.255023Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-4f62250a3479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the functional model from the saved model directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/densenet121-pdd-model-v1/densenet121pdd_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Check the summary of the loaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m--> 168\u001b[0;31m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       printable_module_name='layer')\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 292\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unknown layer: Functional"],"ename":"ValueError","evalue":"Unknown layer: Functional","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}